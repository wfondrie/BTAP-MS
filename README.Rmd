---
title: "BTAP-MS"
author: "William E Fondrie"
date: "5/2/2018"
output: 
    github_document:
        pandoc_args: --webtex
---

# Introduction  

# Methods  

## Setup  
```{r knitrSetup, echo=F, include=FALSE}
knitr::opts_chunk$set(warning = F, message = F)
```  

```{r loadPkgs, results='hide'}
library(tidyverse)
library(broom)
library(ggridges)
library(knitr) # for the kable() function

set.seed(190875) # to ensure reproducibility

# load auxillary functions
source("R/ggplotTheme.R") # Plot themes
full <- 7
half <- 3.33

# Set ggplot2 theme
theme_set(coolTheme)
```


## Load MaxQuant Protein Results  

Protein quantitation data was imported from the MaxQuant `proteinGroups.txt` files. Reverse and contaminant proteins were filtered out. Additionally, we required proteins to be quantified by a minimum of 2 peptides.  
```{r loadData}
prot <- read_tsv("data/combined/txt/proteinGroups.txt") %>%
  filter(!str_detect(`Protein IDs`, "^(REV|CON)__"),
         Peptides >= 2) #%>%
    #select(-ends_with("LRP1_6"))
```

The LFQ intensity columns for each protein were then extracted and reshaped from wide to long format for downstream modeling. The column names indicate the bait and concentration in the following form `[bait]_[3^x nM]`. Thus, `LFQ intensity LRP1B_1` indicates that the GST-LRP1B-ICD was used as bait at a concentration of 3 nM. Samples with the GST suffix indicate that only GST was used.  
```{r extractLFQ}
lfq <- prot %>%
  select(`Protein IDs`, starts_with("LFQ ")) %>%
  gather(samp, lfq, -`Protein IDs`) %>%
  mutate(samp = str_match(samp, " (LRP1.*_.*)$")[ , 2],
         bait = str_match(samp, "(LRP1.*)_")[ , 2], # extract bait used
         conc = str_match(samp, "_(.*)$")[ , 2], # Create concentration column
         conc = ifelse(conc == "GST", 0, 3^as.numeric(conc))) 

# This results in "NAs introduced by coercion" warning, but the problem is
# handled in the final `ifelse()` statement.
```

The number of proteins passing this stage of analysis is:  
```{r numProt1}
lfq %>% 
  group_by(bait) %>%
  summarize(proteins = length(unique(`Protein IDs`))) %>%
  kable()
```

## Handling Missing Values

Zeros, `0`, indicate missing values in the MaxQuant results. With the BTAP-MS experimental design, we expect a number of both values that are missing at random (MAR) and left censored (meaning below the limit of detection). In an effort to distinguish between these, missing values were imputed as the minimum LFQ intensity of the run if all of the intensities at greater bait concentrations were also `0`. All other missing values were assumed to be MAR, and were not considered in modeling.

```{r missingValues}
lfqCensored <- lfq %>%
  group_by(`Protein IDs`, bait) %>%
  filter(sum(lfq) > 0) %>%
  mutate(maxConc = max(conc[lfq > 0]),
         lfq = ifelse(lfq == 0 & conc < maxConc, NA, lfq),
         numNA = sum(is.na(lfq)),
         numZero = sum(lfq == 0, na.rm = T),
         numTotal = length(lfq)) %>%
  group_by(conc, bait) %>%
  #group_by(bait) %>%
  mutate(lfqImp = ifelse(lfq == 0, min(lfq[lfq > 0], na.rm = T), lfq))

lfqCensored %>%
    group_by(bait, conc) %>%
    summarize(minLFQ = min(lfqImp, na.rm = T),
              numMissing = sum(lfq == 0, na.rm = T))
```

In an effort to ensure robust modeling, only proteins with a minimum of 5 valid data points (out of the 9 total), were considered. Additionally, no more than 3 of the data points could be left censored, and in total 4 data points needed to be non-zero.
```{r filtering}
lfqFiltered <- lfqCensored %>%
  group_by(`Protein IDs`, bait) %>%
  filter(numNA <= 4,
         numZero <= 0,
         numTotal - (numNA + numZero) >= 4)
```

The number of proteins passing this stage of analysis is:  
```{r numProt2}
lfqFiltered %>% 
  group_by(bait) %>%
  summarize(proteins = length(unique(`Protein IDs`))) %>%
  kable()
```

## Transforming LFQ Intensities  

The measured LFQ intensities indicate the amount of unbound protein in each sample. To convert this to be proportional to the amount of bound protein, which is needed obtain familiar binding curve shapes, the maximum LFQ intensity for each protein was subtracted and the signed was inversed.
```{r lfqTransform}
lfqModInput <- lfqFiltered %>%
  group_by(`Protein IDs`, bait) %>%
  mutate(response = -(lfqImp - max(lfqImp)))
```

## Nonlinear Modeling  

Each protein was fit to the 1:1 equilibrium binding isotherm using nonlinear least-squares regression. The binding isotherm model takes the form of:  

$$ R = \frac{ [B]_t * R_{max} }{ [B]_t + K_d } $$  

Where given $R$ (the response) and $[B]_t$ (the total bait concentration), we fit the curves to estimate $R_{max}$ (the estimated maximal response) and $K_d$ (the equilibrium dissociation constant). 

```{r modeling}
mods <- lfqModInput %>%
  rename(Protein = `Protein IDs`) %>% #glance() doesn't seem to like the long one
  group_by(Protein, bait) %>%
  filter(!is.na(response)) %>%
  do(models = nls(response ~ (Rmax * conc) / (Kd + conc),
                  data = .,
                  start = list(Kd = 100, Rmax = 4e+07),
                  control = list(maxiter = 200,
                                 warnOnly = T)))

# Retrieve information about model fits
fitInfo <- mods %>% glance(models)

kable(fitInfo[1:5, ])

# Retrieve model parameter values
fitVals <- mods %>% 
  tidy(models) %>%
  mutate(CV = std.error / estimate * 100)

kable(fitVals[1:5, ])
```

Because many of the proteins we measured do not actually interact with the bait proteins, there are a large number of model fits that failed to converge. These were removed from consideration.

```{r removeNotConverged}
fits <- fitInfo %>%
  filter(isConv) %>%
  select(Protein, bait) %>%
  left_join(fitVals)
```

And lastly, we reshape the parameter values to a wide format.  

```{r paramTable}
RmaxTbl <- fits %>%
  filter(term == "Rmax") %>%
  select(Protein, bait, estimate, CV) %>%
  rename(Rmax = estimate, Rmax_CV = CV)

fitTbl <- fits %>%
  filter(term == "Kd") %>%
  left_join(RmaxTbl)

kable(fitTbl[1:5, ])
```

The number of proteins passing this stage of analysis is:  
```{r numProt3}
fitTbl %>% 
  group_by(bait) %>%
  summarize(proteins = length(unique(Protein))) %>%
  kable()
```

## Protein Concentration Estimation  

For the binding isotherm equation above to be valid, we must make the assumption that the conentration of prey protein, $[P]_t$ is much less than the $K_d$. In an effort to verify this assumption, the prey protein concentrations were crudely estimated using the "Total Protein Approach." This approach uses the following estimation to calculate the relative protein concentration in a shotgun proteomics study:    

$$ \frac{Protein~Mass}{Total~Protein~Mass} \approx \frac{Protein~MS~Signal}{Total~MS~Signal}$$  

Thus, given the mass spec signal (raw intensity) of a protein, the total mass spec signal (the sum of raw intensities for a run) we can estimate the relative contributation of a single protein to the total protein mass analyzed. Because the experiment was performed at a total protein conentration of 1 ug/uL, we can then calculate the individual protein concentrations using their molecular weights. 


```{r TPAcalc}
tpaQuan <- prot %>% 
  select(`Protein IDs`, `Gene names`,`Mol. weight [kDa]`, starts_with("Intensity ")) %>%
  gather(samp, intensity, starts_with("Intensity ")) %>%
  rename(MW = `Mol. weight [kDa]`) %>%
  mutate(samp = str_match(samp, " (LRP1.*_.*)$")[ , 2],
         bait = str_match(samp, "(LRP1.*)_")[ , 2], # extract bait used
         conc = str_match(samp, "_(.*)$")[ , 2], # Create concentration column
         conc = ifelse(conc == "GST", 0, 3^as.numeric(conc))) %>%
  group_by(samp) %>%
  mutate(tpa = intensity / sum(intensity, na.rm = T) / (MW * 1000),
         preyConc = tpa * 10^9,
         logPreyConc = log10(preyConc)) 

titer <- tpaQuan %>%
  rename(Protein = `Protein IDs`) %>%
  group_by(Protein) %>%
  summarize(maxConc = max(preyConc, na.rm = T))
```

## Filtering For Sufficient Model Fits

While some estimated $K_d$ values are physically impossible, such as those below zero, others are outside of the range that this experiment was designed to measure. Because the bait concentrations used were between 1 and 2187 nM, we filtered for $K_d$ between 3 nM and 1000 nM. Additionally, higher coefficients of variation (CV) are indicative of poor model fits so we use it as an additional filter.  
```{r filterFits}
interactors <- fitTbl %>%
  left_join(titer) %>%
  filter(estimate > 1, 
         estimate < 1000,
         estimate > maxConc * 10) %>%
  arrange(CV) 
```

The number of proteins passing this stage of analysis is:  
```{r numProt4}
interactors %>% 
  group_by(bait) %>%
  summarize(proteins = length(unique(Protein))) %>%
  kable()
```

## Final interactor list
```{r final filter}
highConfCut <- quantile(interactors$CV, 0.1)

highConf <- interactors %>%
    ungroup() %>%
    filter(CV <= highConfCut) %>%
    arrange(CV) 

highConf %>% 
  group_by(bait) %>%
  summarize(proteins = length(unique(Protein))) %>%
  kable()
```


# Results 
## TPA Estimation Plots
```{r TPAplots}
boxPlot <- tpaQuan %>%
  mutate(bait = paste0("GST-", bait, "-ICD")) %>%
  ggplot(aes(x = as.factor(conc), y = logPreyConc)) +
  geom_violin(fill = ggColors(3)[3]) +
  geom_boxplot(fill = "grey", width = 0.2, outlier.shape = NA) +
  facet_wrap(~ bait, ncol = 1) +
  ylab(expression("log"[10]*"[Protein (nM)]")) +
  xlab("Bait (nM)")

savePlot(boxPlot, w = full/2, h = 4)

overallDist <- tpaQuan %>%
  ggplot(aes(x = logPreyConc)) +
  geom_density(fill = ggColors(3)[3]) +
  xlab(expression("log"[10]*"[Protein (nM)]")) +
  ylab("Density")

savePlot(overallDist, w = full/2, h = 2)


barPlot <- tpaQuan %>%
  group_by(samp) %>%
  filter(intensity > 0) %>%
  summarize(total = length(preyConc),
            `< 1` = sum(preyConc < 1) / total * 100,
            `< 10` = sum(preyConc < 10) / total * 100,
            `< 100` = sum(preyConc < 100)/ total * 100) %>%
  gather(conc, percent, starts_with("<")) %>%
  group_by(conc) %>%
  summarize(avg = mean(percent),
            ci = 1.96 * sd(percent) / sqrt(length(percent))) %>%
  ggplot(aes(x = conc, y = avg, fill = conc)) +
  geom_col(position = "dodge", color = "black") +
  #geom_errorbar(aes(ymax = avg + ci, ymin = avg - ci), width = 0.25) +
  xlab("Protein (nM)") +
  ylab("Number of Proteins (%)") +
  theme(legend.position = "none")

savePlot(barPlot, w = full/2, h = 2)
```

## Evaluating Model Fit Plots
```{r fitEval}
fitScatter <- interactors %>% 
  mutate(Bait = paste0("GST-", bait, "-ICD")) %>%
  ggplot(aes(x = log10(estimate), y = CV, color = Bait)) +
  geom_point() +
  geom_hline(yintercept = highConfCut, linetype = "dashed") + 
  theme(legend.position = c(0, 1),
        legend.justification = c(0, 1),
        legend.background = element_rect(color = "black"),
        legend.title.align = 0.5,
        legend.key.height = unit(0.5, "lines")) +
  xlab(expression("Log"[10]*"[K"[d]~" (nM)]")) +
  ylab("Coefficient of Variation (%)")

savePlot(fitScatter, w = half, h = half)

cvDens <- interactors %>%
  mutate(Bait = paste0("GST-", bait, "-ICD")) %>%
  ggplot(aes(x = CV, fill = bait)) +
  geom_histogram() +
  geom_vline(xintercept = highConfCut, linetype = "dashed") +
  facet_wrap(~Bait, ncol = 1) +
  theme(legend.position = "none") +
  ylab("Number of Proteins") +
  xlab("Coefficient of Variation (%)")
  
savePlot(cvDens, w = half, h = half)
```

## Binding Curve Plots
```{r plotExamples}
plotIsotherm <- function(dat, responseDat = lfqModInput, logScale = F, ncol = 3) {
  
    # Function to create binding curves
    curveFun <- function(Protein, Rmax, estimate, CV, `Gene names`, ..., conc) {
        response <- (Rmax * conc) / (estimate + conc)
        tibble(response = response,
               conc = conc,
               Protein = Protein,
               CV = CV,
               `Gene names` = `Gene names`)
    }
    
    
    if(logScale) {
      x <- 10^(seq(0,log10(2187), length.out = 100))
    } else {
      x <- seq(0, 2187, length.out = 100)
    }
    
    # create curve data
    curveDat <- dat %>%
        select(Protein, estimate, Rmax, CV, `Gene names`)%>%
        pmap_df(curveFun, conc = x) %>%
        ungroup() %>%
        mutate(`Gene names` = fct_reorder(`Gene names`, CV))
    
    # Add response data
    datR <- dat %>% 
        select(Protein, bait, estimate, Rmax, CV, `Gene names`) %>%
        left_join(rename(responseDat, Protein = `Protein IDs`)) %>%
        ungroup() %>%
        mutate(`Gene names` = fct_reorder(`Gene names`, CV))

    # make plot
    p <- datR %>%
        ggplot(aes(x = conc, y = response * 1e-6)) +
        geom_line(data = curveDat, color = ggColors(3)[3]) +
        geom_point(size = 0.5) +
        facet_wrap(~`Gene names`, ncol = ncol, scales = "free_y") +
        ylab(expression("Response (10"^6*")"))
      
    
    if(logScale){ 
        p <- p + scale_x_log10(breaks = c(1, 10, 100, 1000)) 
    } else {
        p <- p + scale_x_continuous(breaks = c(0, 1000, 2000))
    } 
    
    if(length(unique(dat$bait)) == 2) {
        p <- p + xlab("Bait (nM)") 
    } else {
        p <- p + xlab(paste0("GST-", dat$bait[1], "-ICD (nM)"))
    }
    
    p
}

examples <- highConf %>%
    group_by(bait) %>%
    top_n(-3, CV) %>%
    left_join(select(prot, `Protein IDs`, `Gene names`), by = c("Protein" = "Protein IDs"))  

exLrp1b <- examples %>%
    filter(bait == "LRP1B") %>%
    plotIsotherm()
savePlot(exLrp1b, w = half, h = 1.5)

exLogLrp1b <- examples %>%
    filter(bait == "LRP1B") %>%
    plotIsotherm(logScale = T)
savePlot(exLogLrp1b, w = half, h = 1.5)

exLrp1 <- examples %>%
    filter(bait == "LRP1") %>%
    plotIsotherm()
savePlot(exLrp1, w = half, h = 1.5)

exLogLrp1 <- examples %>%
    filter(bait == "LRP1") %>%
    plotIsotherm(logScale = T)
savePlot(exLogLrp1, w = half, h = 1.5)

allLrp1b <- highConf %>%
    filter(bait == "LRP1B") %>%
    left_join(select(prot, `Protein IDs`, `Gene names`), by = c("Protein" = "Protein IDs"))  %>%
    plotIsotherm(logScale = T, ncol = 6) 

allLrp <- highConf %>%
    filter(bait == "LRP1") %>%
    left_join(select(prot, `Protein IDs`, `Gene names`), by = c("Protein" = "Protein IDs"))  %>%
    plotIsotherm(logScale = T, ncol = 6) 
```

## Plot Calculated Affinities and Error Bars
```{r morePlots}
exBar <- highConf %>%
    left_join(select(prot, `Protein IDs`, `Gene names`), by = c("Protein" = "Protein IDs")) %>%
    ungroup() %>%
    mutate(`Gene names` = fct_reorder2(`Gene names`, 
                                       fct_rev(as.factor(bait)), 
                                       estimate, 
                                       .desc = F),
           Bait = paste0("GST-", bait, "-ICD"),
           affinity = ifelse(estimate >= 50, "low", "high")) %>% 
    ggplot(aes(x = `Gene names`, y = estimate, fill = Bait)) +
    geom_col() +
    geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error),
                  width = 0.5) +
    theme(legend.position = "none",
          axis.title.x = element_blank()) +
    facet_grid(.~bait, scales = "free", space = "free") +
    ylab(expression("K"[d]~"(nM)"))
savePlot(exBar, w = 2*half, h = 4)
```


```{r}
a <- highConf %>%
    filter(bait == "LRP1") %>%
    left_join(select(prot, `Protein IDs`, `Gene names`), by = c("Protein" = "Protein IDs")) %>%
    arrange(`Gene names`)
```



